python run_t5_mlm.py \
	--output_dir="./t5-base-pretrain" \
	--model_type="t5" \
	--config_name="t5-base" \
	--tokenizer_name="t5-base" \
	--train_file="pile-base.json" \
	--preprocessing_num_workers="30" \
	--validation_split_percentage="0" \
	--per_device_train_batch_size="16" \
	--per_device_eval_batch_size="8" \
	--do_train \
	--learning_rate="0.005" \
	--weight_decay="0.001" \
	--warmup_steps="2000" \
	--overwrite_output_dir \
	--logging_steps="500" \
	--save_steps="2400" \
	--eval_steps="2500" \
	--max_train_samples="1000" \
